{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets tokenizers seqeval -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-10T04:03:51.705350Z","iopub.execute_input":"2023-06-10T04:03:51.706076Z","iopub.status.idle":"2023-06-10T04:04:06.144357Z","shell.execute_reply.started":"2023-06-10T04:03:51.706040Z","shell.execute_reply":"2023-06-10T04:04:06.143103Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import datasets \nimport numpy as np \nfrom transformers import BertTokenizerFast \nfrom transformers import DataCollatorForTokenClassification \nfrom transformers import AutoModelForTokenClassification \n\nconll2003 = datasets.load_dataset(\"conll2003\") ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:06.147079Z","iopub.execute_input":"2023-06-10T04:04:06.148779Z","iopub.status.idle":"2023-06-10T04:04:27.705402Z","shell.execute_reply.started":"2023-06-10T04:04:06.148742Z","shell.execute_reply":"2023-06-10T04:04:27.704344Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5bedb19a1e54b5ebce1399d7c1a885b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37cc04a5e26340729c67f03a0d54df47"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset conll2003/conll2003 (download: 959.94 KiB, generated: 9.78 MiB, post-processed: Unknown size, total: 10.72 MiB) to /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/63f4ebd1bcb7148b1644497336fd74643d4ce70123334431a3c053b7ee4e96ee...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87727b6e9b924618b68d1c2a91e76820"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14042 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3251 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3454 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset conll2003 downloaded and prepared to /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/63f4ebd1bcb7148b1644497336fd74643d4ce70123334431a3c053b7ee4e96ee. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8c52eb21b914c648ebef4ce0028eb32"}},"metadata":{}}]},{"cell_type":"code","source":"conll2003","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:27.706828Z","iopub.execute_input":"2023-06-10T04:04:27.707308Z","iopub.status.idle":"2023-06-10T04:04:27.715109Z","shell.execute_reply.started":"2023-06-10T04:04:27.707272Z","shell.execute_reply":"2023-06-10T04:04:27.713989Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14042\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3251\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3454\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"conll2003.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:27.718556Z","iopub.execute_input":"2023-06-10T04:04:27.718892Z","iopub.status.idle":"2023-06-10T04:04:27.730471Z","shell.execute_reply.started":"2023-06-10T04:04:27.718861Z","shell.execute_reply":"2023-06-10T04:04:27.729151Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'train': (14042, 5), 'validation': (3251, 5), 'test': (3454, 5)}"},"metadata":{}}]},{"cell_type":"code","source":"conll2003[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:27.731742Z","iopub.execute_input":"2023-06-10T04:04:27.732572Z","iopub.status.idle":"2023-06-10T04:04:27.743444Z","shell.execute_reply.started":"2023-06-10T04:04:27.732539Z","shell.execute_reply":"2023-06-10T04:04:27.742591Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'id': '0',\n 'tokens': ['EU',\n  'rejects',\n  'German',\n  'call',\n  'to',\n  'boycott',\n  'British',\n  'lamb',\n  '.'],\n 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"},"metadata":{}}]},{"cell_type":"code","source":"conll2003[\"train\"][1]","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:27.744696Z","iopub.execute_input":"2023-06-10T04:04:27.745492Z","iopub.status.idle":"2023-06-10T04:04:27.754164Z","shell.execute_reply.started":"2023-06-10T04:04:27.745461Z","shell.execute_reply":"2023-06-10T04:04:27.753221Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'id': '1',\n 'tokens': ['Peter', 'Blackburn'],\n 'pos_tags': [22, 22],\n 'chunk_tags': [11, 12],\n 'ner_tags': [1, 2]}"},"metadata":{}}]},{"cell_type":"code","source":"conll2003[\"train\"].features[\"ner_tags\"] # all the ner tags","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:27.755481Z","iopub.execute_input":"2023-06-10T04:04:27.756173Z","iopub.status.idle":"2023-06-10T04:04:27.764361Z","shell.execute_reply.started":"2023-06-10T04:04:27.756132Z","shell.execute_reply":"2023-06-10T04:04:27.763395Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"},"metadata":{}}]},{"cell_type":"code","source":"conll2003['train'].description","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:27.765637Z","iopub.execute_input":"2023-06-10T04:04:27.766583Z","iopub.status.idle":"2023-06-10T04:04:27.775325Z","shell.execute_reply.started":"2023-06-10T04:04:27.766550Z","shell.execute_reply":"2023-06-10T04:04:27.774624Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\\nfour types of named entities: persons, locations, organizations and names of miscellaneous entities that do\\nnot belong to the previous three groups.\\n\\nThe CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\\na separate line and there is an empty line after each sentence. The first item on each line is a word, the second\\na part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\\nand the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\\nif two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\\nB-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\\ntagging scheme, whereas the original dataset uses IOB1.\\n\\nFor more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\\n'"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer  = BertTokenizerFast.from_pretrained(\"bert-base-uncased\") ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:27.776637Z","iopub.execute_input":"2023-06-10T04:04:27.777174Z","iopub.status.idle":"2023-06-10T04:04:28.331563Z","shell.execute_reply.started":"2023-06-10T04:04:27.777135Z","shell.execute_reply":"2023-06-10T04:04:28.330682Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"743e5fdca7044b2eaa9eb8c978bf77a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e039653d2014b00a2d4224562929252"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aac59d276fb5438687be5046113b2a28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aceb098f42184dd3b501422c58fa73cb"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Example of  bert tokenization \n\nbut whenever using bert model, or any other model, use its own tokenizer, where as in case of other machine learing model we have to use the tf idf or bag words vector tokenization","metadata":{}},{"cell_type":"code","source":"conll2003[\"train\"][1] # we are going to apply our model on tokens. ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:28.335889Z","iopub.execute_input":"2023-06-10T04:04:28.336190Z","iopub.status.idle":"2023-06-10T04:04:28.344332Z","shell.execute_reply.started":"2023-06-10T04:04:28.336163Z","shell.execute_reply":"2023-06-10T04:04:28.343448Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'id': '1',\n 'tokens': ['Peter', 'Blackburn'],\n 'pos_tags': [22, 22],\n 'chunk_tags': [11, 12],\n 'ner_tags': [1, 2]}"},"metadata":{}}]},{"cell_type":"code","source":"example_text = conll2003['train'][1]\ntokenized_input = tokenizer(example_text[\"tokens\"], is_split_into_words=True)\ntokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\nword_ids = tokenized_input.word_ids()\nprint(word_ids)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:28.345760Z","iopub.execute_input":"2023-06-10T04:04:28.346480Z","iopub.status.idle":"2023-06-10T04:04:28.362530Z","shell.execute_reply.started":"2023-06-10T04:04:28.346449Z","shell.execute_reply":"2023-06-10T04:04:28.361580Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[None, 0, 1, None]\n","output_type":"stream"}]},{"cell_type":"code","source":"conll2003[\"train\"][0] # we are going to apply our model on tokens. ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:28.363882Z","iopub.execute_input":"2023-06-10T04:04:28.364481Z","iopub.status.idle":"2023-06-10T04:04:28.372381Z","shell.execute_reply.started":"2023-06-10T04:04:28.364451Z","shell.execute_reply":"2023-06-10T04:04:28.371272Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'id': '0',\n 'tokens': ['EU',\n  'rejects',\n  'German',\n  'call',\n  'to',\n  'boycott',\n  'British',\n  'lamb',\n  '.'],\n 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"},"metadata":{}}]},{"cell_type":"code","source":"example_text = conll2003['train'][0]\ntokenized_input = tokenizer(example_text[\"tokens\"], is_split_into_words=True)\ntokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\nword_ids = tokenized_input.word_ids()\nprint(word_ids) ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:28.374037Z","iopub.execute_input":"2023-06-10T04:04:28.374776Z","iopub.status.idle":"2023-06-10T04:04:28.383177Z","shell.execute_reply.started":"2023-06-10T04:04:28.374744Z","shell.execute_reply":"2023-06-10T04:04:28.382085Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"1. EU -> 1\n2. rejects -> 2\nand so on. \nHere we can see that how are assigned with an number. \n\n#### None is assigned as start and and end of sentence. which is replace by cls in the first place and in the end it is replaced by sep","metadata":{}},{"cell_type":"code","source":"tokenized_input","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:28.384768Z","iopub.execute_input":"2023-06-10T04:04:28.385460Z","iopub.status.idle":"2023-06-10T04:04:28.393624Z","shell.execute_reply.started":"2023-06-10T04:04:28.385427Z","shell.execute_reply":"2023-06-10T04:04:28.392611Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"markdown","source":"* 101 -> cls\n* 102 -> sep \n* and other words are represented with an unique id","metadata":{}},{"cell_type":"code","source":"# lets see the assigned id \ntokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\ntokens\n     ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:28.395112Z","iopub.execute_input":"2023-06-10T04:04:28.395843Z","iopub.status.idle":"2023-06-10T04:04:28.404701Z","shell.execute_reply.started":"2023-06-10T04:04:28.395806Z","shell.execute_reply":"2023-06-10T04:04:28.403722Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"['[CLS]',\n 'eu',\n 'rejects',\n 'german',\n 'call',\n 'to',\n 'boycott',\n 'british',\n 'lamb',\n '.',\n '[SEP]']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Higher level overview\n","metadata":{}},{"cell_type":"code","source":"len(tokens)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:28.406194Z","iopub.execute_input":"2023-06-10T04:04:28.406867Z","iopub.status.idle":"2023-06-10T04:04:28.416068Z","shell.execute_reply.started":"2023-06-10T04:04:28.406835Z","shell.execute_reply":"2023-06-10T04:04:28.415247Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"11"},"metadata":{}}]},{"cell_type":"code","source":"len(conll2003['train'][0]['ner_tags'])","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:28.417541Z","iopub.execute_input":"2023-06-10T04:04:28.418200Z","iopub.status.idle":"2023-06-10T04:04:28.427757Z","shell.execute_reply.started":"2023-06-10T04:04:28.418170Z","shell.execute_reply":"2023-06-10T04:04:28.426875Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"9"},"metadata":{}}]},{"cell_type":"code","source":"conll2003['train'][0]['ner_tags']","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:28.428973Z","iopub.execute_input":"2023-06-10T04:04:28.429897Z","iopub.status.idle":"2023-06-10T04:04:28.439867Z","shell.execute_reply.started":"2023-06-10T04:04:28.429867Z","shell.execute_reply":"2023-06-10T04:04:28.438959Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[3, 0, 7, 0, 0, 0, 7, 0, 0]"},"metadata":{}}]},{"cell_type":"markdown","source":"### Above in the training data, its not counting the the sep and cls,its only counting the words, so we have to add the cls or sep tokens for our model manuallay in the training data","metadata":{}},{"cell_type":"code","source":"len(example_text['ner_tags']), len(tokenized_input[\"input_ids\"]) # see the difference between them ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:28.441326Z","iopub.execute_input":"2023-06-10T04:04:28.442021Z","iopub.status.idle":"2023-06-10T04:04:28.451630Z","shell.execute_reply.started":"2023-06-10T04:04:28.441990Z","shell.execute_reply":"2023-06-10T04:04:28.450951Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(9, 11)"},"metadata":{}}]},{"cell_type":"markdown","source":"# The below function tokenize_and_align_labels does 2 jobs\n\n* set –100 as the label for these special tokens and the subwords we wish to mask during training\n* mask the subword representations after the first subword\n* Then we align the labels with the token ids using the strategy we picked:","metadata":{}},{"cell_type":"code","source":"def tokenize_and_align_labels(examples, label_all_tokens=True):\n    tokenized_inputs = tokenizer(examples['tokens'], truncation = True, is_split_into_words = True)\n    labels = []\n    for i, label in enumerate(examples[\"ner_tags\"]):\n        word_ids  = tokenized_inputs.word_ids(batch_index= i) # creates a list indiating the word corresponding to each token\n        previous_word_idx  = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None: \n                label_ids.append(-100)\n            elif word_idx  != previous_word_idx:\n                label_ids.append(label[word_idx])\n            else:\n                label_ids.append(label[word_idx] if label_all_tokens else -100)\n                \n            previous_word_idx = word_idx\n        \n        labels.append(label_ids)\n    \n    tokenized_inputs[\"labels\"] = labels \n    return tokenized_inputs \n        ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:28.453095Z","iopub.execute_input":"2023-06-10T04:04:28.453950Z","iopub.status.idle":"2023-06-10T04:04:28.462896Z","shell.execute_reply.started":"2023-06-10T04:04:28.453918Z","shell.execute_reply":"2023-06-10T04:04:28.462107Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"conll2003['train'][0]\n","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:28.464351Z","iopub.execute_input":"2023-06-10T04:04:28.465106Z","iopub.status.idle":"2023-06-10T04:04:28.479382Z","shell.execute_reply.started":"2023-06-10T04:04:28.465075Z","shell.execute_reply":"2023-06-10T04:04:28.478476Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'id': '0',\n 'tokens': ['EU',\n  'rejects',\n  'German',\n  'call',\n  'to',\n  'boycott',\n  'British',\n  'lamb',\n  '.'],\n 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"},"metadata":{}}]},{"cell_type":"code","source":"q = tokenize_and_align_labels(conll2003['train'][0:1]) \nprint(q) ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:28.481061Z","iopub.execute_input":"2023-06-10T04:04:28.481741Z","iopub.status.idle":"2023-06-10T04:04:28.493567Z","shell.execute_reply.started":"2023-06-10T04:04:28.481710Z","shell.execute_reply":"2023-06-10T04:04:28.489487Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"{'input_ids': [[101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, -100]]}\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfor token, label in zip(tokenizer.convert_ids_to_tokens(q[\"input_ids\"][0]),q[\"labels\"][0]): \n    print(f\"{token:_<40} {label}\") ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:28.495102Z","iopub.execute_input":"2023-06-10T04:04:28.495951Z","iopub.status.idle":"2023-06-10T04:04:28.503155Z","shell.execute_reply.started":"2023-06-10T04:04:28.495871Z","shell.execute_reply":"2023-06-10T04:04:28.502176Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"[CLS]___________________________________ -100\neu______________________________________ 3\nrejects_________________________________ 0\ngerman__________________________________ 7\ncall____________________________________ 0\nto______________________________________ 0\nboycott_________________________________ 0\nbritish_________________________________ 7\nlamb____________________________________ 0\n._______________________________________ 0\n[SEP]___________________________________ -100\n","output_type":"stream"}]},{"cell_type":"code","source":"## Applying on entire data\ntokenized_datasets = conll2003.map(tokenize_and_align_labels, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:28.504741Z","iopub.execute_input":"2023-06-10T04:04:28.505036Z","iopub.status.idle":"2023-06-10T04:04:32.814518Z","shell.execute_reply.started":"2023-06-10T04:04:28.505010Z","shell.execute_reply":"2023-06-10T04:04:32.813607Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"189e17752d6646a7b778b2be528fbd69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cc5c4d672af4d258e31494a5dd21873"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4059fab96d214751baa3729b563b6346"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Tokenized data example","metadata":{}},{"cell_type":"code","source":"tokenized_datasets['train'][0]","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:32.815815Z","iopub.execute_input":"2023-06-10T04:04:32.816260Z","iopub.status.idle":"2023-06-10T04:04:32.827396Z","shell.execute_reply.started":"2023-06-10T04:04:32.816225Z","shell.execute_reply":"2023-06-10T04:04:32.825088Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'id': '0',\n 'tokens': ['EU',\n  'rejects',\n  'German',\n  'call',\n  'to',\n  'boycott',\n  'British',\n  'lamb',\n  '.'],\n 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0],\n 'input_ids': [101,\n  7327,\n  19164,\n  2446,\n  2655,\n  2000,\n  17757,\n  2329,\n  12559,\n  1012,\n  102],\n 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n 'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, -100]}"},"metadata":{}}]},{"cell_type":"markdown","source":" # Model Defining ","metadata":{}},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=9) # assigning the number of labels in the dataset","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:32.828778Z","iopub.execute_input":"2023-06-10T04:04:32.829192Z","iopub.status.idle":"2023-06-10T04:04:37.945317Z","shell.execute_reply.started":"2023-06-10T04:04:32.829153Z","shell.execute_reply":"2023-06-10T04:04:37.944452Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ed885f3087e45a88985578101137da1"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Define training args","metadata":{}},{"cell_type":"code","source":"! pip install --upgrade accelerate","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:37.946869Z","iopub.execute_input":"2023-06-10T04:04:37.947226Z","iopub.status.idle":"2023-06-10T04:04:49.688350Z","shell.execute_reply.started":"2023-06-10T04:04:37.947193Z","shell.execute_reply":"2023-06-10T04:04:49.687145Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.12.0)\nCollecting accelerate\n  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.4.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.12.0\n    Uninstalling accelerate-0.12.0:\n      Successfully uninstalled accelerate-0.12.0\nSuccessfully installed accelerate-0.20.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"! pip install transformers==4.28.0","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:04:49.699234Z","iopub.execute_input":"2023-06-10T04:04:49.701513Z","iopub.status.idle":"2023-06-10T04:05:10.702891Z","shell.execute_reply.started":"2023-06-10T04:04:49.701470Z","shell.execute_reply":"2023-06-10T04:05:10.701664Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting transformers==4.28.0\n  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (0.14.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (0.13.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.0) (4.64.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.28.0) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.0) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.0) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.0) (2023.5.7)\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.29.2\n    Uninstalling transformers-4.29.2:\n      Successfully uninstalled transformers-4.29.2\nSuccessfully installed transformers-4.28.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:05:10.704899Z","iopub.execute_input":"2023-06-10T04:05:10.705663Z","iopub.status.idle":"2023-06-10T04:05:10.731843Z","shell.execute_reply.started":"2023-06-10T04:05:10.705618Z","shell.execute_reply":"2023-06-10T04:05:10.730979Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer \n\n\nargs = TrainingArguments( \n\"test-ner\",\nevaluation_strategy = \"epoch\", \nlearning_rate=2e-5, \nper_device_train_batch_size=16, \nper_device_eval_batch_size=16, \nnum_train_epochs=3, \nweight_decay=0.01, \n) ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:05:10.733288Z","iopub.execute_input":"2023-06-10T04:05:10.733981Z","iopub.status.idle":"2023-06-10T04:05:10.802599Z","shell.execute_reply.started":"2023-06-10T04:05:10.733948Z","shell.execute_reply":"2023-06-10T04:05:10.801732Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer) ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:05:10.803921Z","iopub.execute_input":"2023-06-10T04:05:10.804655Z","iopub.status.idle":"2023-06-10T04:05:10.809065Z","shell.execute_reply.started":"2023-06-10T04:05:10.804623Z","shell.execute_reply":"2023-06-10T04:05:10.807905Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"metric = datasets.load_metric(\"seqeval\") ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:05:10.810609Z","iopub.execute_input":"2023-06-10T04:05:10.811291Z","iopub.status.idle":"2023-06-10T04:05:11.197857Z","shell.execute_reply.started":"2023-06-10T04:05:10.811239Z","shell.execute_reply":"2023-06-10T04:05:11.196719Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52ad904470274aedaa9cd6ce2e2b05e2"}},"metadata":{}}]},{"cell_type":"markdown","source":"### seqeval \nis a Python framework for sequence labeling evaluation. seqeval can evaluate the performance of chunking tasks such as named-entity recognition, part-of-speech tagging, semantic role labeling and so on.\n\n#### It will return the precision, recall and f1 score, all the score. ","metadata":{}},{"cell_type":"markdown","source":"# Test the matrix on an example","metadata":{}},{"cell_type":"code","source":"example = conll2003['train'][0]\nexample","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:05:11.199123Z","iopub.execute_input":"2023-06-10T04:05:11.199569Z","iopub.status.idle":"2023-06-10T04:05:11.209279Z","shell.execute_reply.started":"2023-06-10T04:05:11.199537Z","shell.execute_reply":"2023-06-10T04:05:11.208157Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"{'id': '0',\n 'tokens': ['EU',\n  'rejects',\n  'German',\n  'call',\n  'to',\n  'boycott',\n  'British',\n  'lamb',\n  '.'],\n 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"},"metadata":{}}]},{"cell_type":"code","source":"label_list = conll2003[\"train\"].features[\"ner_tags\"].feature.names \nlabel_list","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:05:11.210902Z","iopub.execute_input":"2023-06-10T04:05:11.211230Z","iopub.status.idle":"2023-06-10T04:05:11.219189Z","shell.execute_reply.started":"2023-06-10T04:05:11.211198Z","shell.execute_reply":"2023-06-10T04:05:11.218217Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"},"metadata":{}}]},{"cell_type":"code","source":"for i in example[\"ner_tags\"]:\n  print(i)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:05:11.220554Z","iopub.execute_input":"2023-06-10T04:05:11.221076Z","iopub.status.idle":"2023-06-10T04:05:11.235294Z","shell.execute_reply.started":"2023-06-10T04:05:11.221046Z","shell.execute_reply":"2023-06-10T04:05:11.234361Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"3\n0\n7\n0\n0\n0\n7\n0\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"labels = [label_list[i] for i in example[\"ner_tags\"]] \nlabels","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:05:11.236325Z","iopub.execute_input":"2023-06-10T04:05:11.236624Z","iopub.status.idle":"2023-06-10T04:05:11.247472Z","shell.execute_reply.started":"2023-06-10T04:05:11.236601Z","shell.execute_reply":"2023-06-10T04:05:11.246395Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"},"metadata":{}}]},{"cell_type":"code","source":"metric.compute(predictions=[labels], references=[labels]) ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:05:11.248581Z","iopub.execute_input":"2023-06-10T04:05:11.249236Z","iopub.status.idle":"2023-06-10T04:05:11.267698Z","shell.execute_reply.started":"2023-06-10T04:05:11.249204Z","shell.execute_reply":"2023-06-10T04:05:11.266792Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"{'MISC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n 'overall_precision': 1.0,\n 'overall_recall': 1.0,\n 'overall_f1': 1.0,\n 'overall_accuracy': 1.0}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Compute Metrics","metadata":{}},{"cell_type":"markdown","source":"This compute_metrics() function first takes the argmax of the logits to convert them to predictions (as usual, the logits and the probabilities are in the same order, so we don’t need to apply the softmax). Then we have to convert both labels and predictions from integers to strings. We remove all the values where the label is -100, then pass the results to the metric.compute() method:","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_preds): \n    pred_logits, labels = eval_preds \n    \n    pred_logits = np.argmax(pred_logits, axis=2) \n    # the logits and the probabilities are in the same order,\n    # so we don’t need to apply the softmax\n    \n    # We remove all the values where the label is -100\n    predictions = [ \n        [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100] \n        for prediction, label in zip(pred_logits, labels) \n    ] \n    \n    true_labels = [ \n      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100] \n       for prediction, label in zip(pred_logits, labels) \n   ] \n    results = metric.compute(predictions=predictions, references=true_labels)\n\n    return { \n          \"precision\": results[\"overall_precision\"], \n          \"recall\": results[\"overall_recall\"], \n          \"f1\": results[\"overall_f1\"], \n          \"accuracy\": results[\"overall_accuracy\"], \n  } \n     ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:05:41.398572Z","iopub.execute_input":"2023-06-10T04:05:41.398937Z","iopub.status.idle":"2023-06-10T04:05:41.406751Z","shell.execute_reply.started":"2023-06-10T04:05:41.398908Z","shell.execute_reply":"2023-06-10T04:05:41.405776Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"\ntrainer = Trainer( \n   model, \n   args, \n   train_dataset=tokenized_datasets[\"train\"], \n   eval_dataset=tokenized_datasets[\"validation\"], \n   data_collator=data_collator, \n   tokenizer=tokenizer, \n   compute_metrics=compute_metrics \n) ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:05:41.903088Z","iopub.execute_input":"2023-06-10T04:05:41.903465Z","iopub.status.idle":"2023-06-10T04:05:47.046865Z","shell.execute_reply.started":"2023-06-10T04:05:41.903428Z","shell.execute_reply":"2023-06-10T04:05:47.045891Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:05:54.789333Z","iopub.execute_input":"2023-06-10T04:05:54.789766Z","iopub.status.idle":"2023-06-10T04:13:25.724046Z","shell.execute_reply.started":"2023-06-10T04:05:54.789736Z","shell.execute_reply":"2023-06-10T04:13:25.720231Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230610_040734-iv02qh17</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/brac/huggingface/runs/iv02qh17' target=\"_blank\">vague-moon-1</a></strong> to <a href='https://wandb.ai/brac/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/brac/huggingface' target=\"_blank\">https://wandb.ai/brac/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/brac/huggingface/runs/iv02qh17' target=\"_blank\">https://wandb.ai/brac/huggingface/runs/iv02qh17</a>"},"metadata":{}},{"name":"stderr","text":"You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2634/2634 05:18, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.216600</td>\n      <td>0.062614</td>\n      <td>0.923520</td>\n      <td>0.932095</td>\n      <td>0.927788</td>\n      <td>0.982541</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.046300</td>\n      <td>0.060077</td>\n      <td>0.924065</td>\n      <td>0.942052</td>\n      <td>0.932971</td>\n      <td>0.983796</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.026500</td>\n      <td>0.057563</td>\n      <td>0.934542</td>\n      <td>0.945520</td>\n      <td>0.939999</td>\n      <td>0.986163</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2634, training_loss=0.07741440283862949, metrics={'train_runtime': 450.8769, 'train_samples_per_second': 93.431, 'train_steps_per_second': 5.842, 'total_flos': 1019599557281136.0, 'train_loss': 0.07741440283862949, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Saving model ","metadata":{}},{"cell_type":"code","source":"\n## Save model\nmodel.save_pretrained(\"ner_model\")","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:14:10.075351Z","iopub.execute_input":"2023-06-10T04:14:10.076315Z","iopub.status.idle":"2023-06-10T04:14:10.764458Z","shell.execute_reply.started":"2023-06-10T04:14:10.076276Z","shell.execute_reply":"2023-06-10T04:14:10.763154Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"## Save tokenizer\ntokenizer.save_pretrained(\"tokenizer\")","metadata":{"execution":{"iopub.status.busy":"2023-06-10T04:14:20.959531Z","iopub.execute_input":"2023-06-10T04:14:20.959925Z","iopub.status.idle":"2023-06-10T04:14:21.026163Z","shell.execute_reply.started":"2023-06-10T04:14:20.959898Z","shell.execute_reply":"2023-06-10T04:14:21.025107Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"('tokenizer/tokenizer_config.json',\n 'tokenizer/special_tokens_map.json',\n 'tokenizer/vocab.txt',\n 'tokenizer/added_tokens.json',\n 'tokenizer/tokenizer.json')"},"metadata":{}}]}]}